Q1. Document Classification: â€œpredictable no funâ€

We compute NaÃ¯ve Bayes scores:

P(classâˆ£doc)âˆP(class)âˆP(wordâˆ£class)
Positive score

Score pos=0.5Ã—0.10Ã—0.05Ã—0.02

Step by step:

0.10 Ã— 0.05 = 0.005

0.005 Ã— 0.02 = 0.0001

0.0001 Ã— 0.5 = 0.00005

Score pos=5Ã—10âˆ’5
ğŸ”¹ Negative score

Score neg=0.5Ã—0.40Ã—0.30Ã—0.25

Step by step:

0.40 Ã— 0.30 = 0.12

0.12 Ã— 0.25 = 0.03

0.03 Ã— 0.5 = 0.015

ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ‘›ğ‘’ğ‘”=0.015
Score neg=0.015
 Classification Decision
0.015
â‰«
0.00005
0.015â‰«0.00005

Assigned class: âœ Negative

Q2. Harms of Classification
1ï¸ Representational Harm

Definition:
When a system reinforces stereotypes or portrays a group unfairly.

Kiritchenko & Mohammad (2018)
They showed sentiment models rated sentences containing words linked
 to women or minorities more negatively than identical sentences with neutral words.


2ï¸ Risk of Censorship in Toxicity Systems

From Dixon et al. (2018); Oliva et al. (2021):

 Toxicity classifiers often flag identity terms (e.g., â€œgayâ€, â€œMuslimâ€) as toxic.

Risk:
Legitimate speech by marginalized communities gets suppressed.

3ï¸ Why Classifiers Perform Worse on AAE or Indian English

Reasons include:

Training data dominated by Standard American English

Dialect grammar differs (not errors)

Vocabulary & syntax differs

Key issue: linguistic diversity â‰  poor language.

 Q3. Bigram Probabilities
1ï¸ Sentence Probabilities (MLE)
S1: <s> I love NLP </s>

P=P(Iâˆ£<s>)Ã—P(loveâˆ£I)Ã—P(NLPâˆ£love)Ã—P(</s>âˆ£NLP)

From counts:

P(I|<s>) = 2/3

P(love|I) = 2/2 = 1

P(NLP|love) = 1/2

P(</s>|NLP) = 1/1 = 1


P(S1)=32Ã—1Ã—21Ã—1=31â‰ˆ0.333
S2: <s> I love deep learning </s>

P=32Ã—1Ã—21Ã—1Ã—21

Step-by-step:

deep|love = 1/2

learning|deep = 2/2 = 1

</s>|learning = 1/2

P(S2)=32Ã—1Ã—21Ã—1Ã—21=61â‰ˆ0.167
 More probable sentence

S1 is more probable (0.333 > 0.167)

2ï¸ Zero-Probability Problem
ğŸ”¹ MLE

Counts after "ate": 6+3+2+1 = 12

P(noodleâˆ£ate)=0
 Why this is a problem

If any word has probability 0:

P(sentence)=0

This breaks:

sentence scoring

perplexity calculations

ğŸ”¹ Laplace smoothing

P=12+100+1=221â‰ˆ0.045
âœ… Q4. Backoff Model
1ï¸ P(cats | I like)

Trigram count:
I like cats = 1
I like total = 2

P=1/2=0.5
2ï¸ P(dogs | You like)

Trigram unseen â†’ backoff to bigram:

P(dogsâˆ£like)=1/3
3ï¸ Why backoff is necessary

Because many trigrams never appear in small corpora.
Backoff prevents zero probabilities.

âœ… Q5. Confusion Matrix Metrics

Matrix:

System\Gold	Cat	Dog	Rabbit
Cat	5	10	5
Dog	15	20	10
Rabbit	0	15	10
1ï¸ Per-Class Precision & Recall
 Cat

Precision = 5 / (5+10+5) = 5/20 = 0.25

Recall = 5 / (5+15+0) = 5/20 = 0.25

 Dog

Precision = 20 / (15+20+10) = 20/45 â‰ˆ 0.44

Recall = 20 / (10+20+15) = 20/45 â‰ˆ 0.44

 Rabbit

Precision = 10 / (5+10+10) = 10/25 = 0.40

Recall = 10 / (5+10+10) = 10/25 = 0.40

2ï¸ Macro vs Micro
Macro Average
Precision=(0.25+0.44+0.40)/3â‰ˆ0.36
Recall=(0.25+0.44+0.40)/3â‰ˆ0.36
Micro Average

Total TP = 5+20+10 = 35
Total predictions = 90
Total actual = 90

Micro Precision=35/90â‰ˆ0.39

Micro Recall=35/90â‰ˆ0.39
Difference

Macro: treats all classes equally

Micro: favors frequent classes